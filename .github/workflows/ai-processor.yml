name: AI Article Processor

on:
  schedule:
    # Runs at 01:00 UTC every day (after all scrapers complete)
    - cron: '0 1 * * *'
  workflow_dispatch: # Allows manual triggering

jobs:
  process-articles:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        
    - name: Run AI article processor (Enhanced Consolidated)
      env:
        SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
        SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
      run: |
        echo "ü§ñ Starting Enhanced AI article processor (Consolidated) at $(date)"
        echo "‚ú® Features: Enhanced climate filtering, company name extraction, post-validation"
        python ai_processor_consolidated.py
        echo "‚úÖ Enhanced AI processing consolidated completed at $(date)"
        
    - name: Log completion
      if: success()
      run: echo "‚úÖ AI processor ran successfully"
      
    - name: Log failure
      if: failure()
      run: echo "‚ùå AI processor failed"
